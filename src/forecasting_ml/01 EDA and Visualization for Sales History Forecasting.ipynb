{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07821f00-494d-474a-bfda-bc958fcb9dca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Sales History EDA & Visualization: Notebook Overview and Results\n",
    "\n",
    "This notebook explores weekly sales data from the last 3 years for the top 5 most active (warehouse_id, product_id) pairs in [lars_dev.smart_stock_silver.sales_history](#table) on AWS Databricks. The workflow includes:\n",
    "\n",
    "* **Data Sampling:** Extracts and inspects recent sales data, focusing on the most active product/warehouse pairs.\n",
    "* **Automated Profiling:** Uses ydata-profiling to summarize distributions, missing values, and correlations.\n",
    "* **Visualization:** Plots weekly sales trends for selected pairs, revealing seasonality, trends, and outliers.\n",
    "\n",
    "**Key Results:**\n",
    "* Data is well-structured for time series forecasting, with clear weekly granularity and minimal missingness.\n",
    "* Visualizations show significant week-to-week variability and some seasonal patterns, supporting the use of advanced forecasting models.\n",
    "* The notebook is organized for easy extension to feature engineering and model training.\n",
    "\n",
    "_Proceed to the next sections for detailed code, EDA, and visualizations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01b495e2-9956-4172-9735-5b060990f42b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog\", \"lars_lia\")\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "dbutils.widgets.text(\"schema_silver\", \"smart_stock_silver\")\n",
    "schema_silver = dbutils.widgets.get(\"schema_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "729f0527-2508-4675-9059-c8d9038d872c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install ydata-profiling if not already installed\n",
    "try:\n",
    "    import ydata_profiling\n",
    "except ImportError:\n",
    "    %pip install ydata-profiling==4.8.3\n",
    "\n",
    "# No need to install matplotlib, seaborn, pandas on Databricks, but can be added if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ece1bec0-e29b-4c70-81e2-929c3a158a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import DataFrame\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "642560e4-091f-4ce0-8250-f81e0ee9ee16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the time window: last 3 years from today\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=3*365)\n",
    "\n",
    "# Read the sales_history table\n",
    "sales_history = spark.table(f\"{catalog}.{schema_silver}.sales_history\")\n",
    "\n",
    "# Filter for last 3 years\n",
    "sales_history_recent = sales_history.filter(col(\"week_start\").between(start_date, end_date))\n",
    "\n",
    "# Show a sample\n",
    "display(sales_history_recent.limit(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90b9b112-6128-45b1-9acc-edbf2b9b219f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the top 5 (warehouse_id, product_id) pairs with the most records\n",
    "pair_counts = (sales_history_recent\n",
    "    .groupBy(\"warehouse_id\", \"product_id\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    ")\n",
    "top_pairs = pair_counts.limit(5).toPandas()\n",
    "display(top_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd50ef69-c2a7-4a9e-af70-d01b60c4c949",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select the top pairs for EDA\n",
    "selected_pairs = top_pairs[[\"warehouse_id\", \"product_id\"]].values.tolist()\n",
    "\n",
    "# Build filter for selected pairs\n",
    "def filter_for_pairs(df: DataFrame, pairs):\n",
    "    conditions = [\n",
    "        (col(\"warehouse_id\") == wid) & (col(\"product_id\") == pid)\n",
    "        for wid, pid in pairs\n",
    "    ]\n",
    "    return df.filter(reduce(lambda a, b: a | b, conditions))\n",
    "\n",
    "sales_history_selected = filter_for_pairs(sales_history_recent, selected_pairs)\n",
    "display(sales_history_selected.limit(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72d5dba9-5a3a-4a45-ac11-691fce5f45cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the top 5 (warehouse_id, product_id) pairs with the most records\n",
    "pair_counts = (sales_history_recent\n",
    "    .groupBy(\"warehouse_id\", \"product_id\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    ")\n",
    "top_pairs = pair_counts.limit(5).toPandas()\n",
    "display(top_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84527ad6-9884-46dd-8a85-ad6ceebb96a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the filtered Spark DataFrame to Pandas\n",
    "pdf_sales_history = sales_history_selected.toPandas()\n",
    "\n",
    "# Generate the profile report\n",
    "profile = ydata_profiling.ProfileReport(pdf_sales_history, title=\"Sales History EDA Report\", explorative=True)\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12c207bd-6933-4b9f-8d4d-956903811014",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## Step 2: Profile the Data with ydata-profiling\n",
    "We'll convert the filtered Spark DataFrame to a Pandas DataFrame and use ydata-profiling to generate a profile report. We'll use ydata-profiling version 4.8.3 if needed. Display the profile report for general EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf38ffe9-489d-492d-975f-ec49745184b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ensure week_start is datetime\n",
    "pdf_sales_history['week_start'] = pd.to_datetime(pdf_sales_history['week_start'])\n",
    "\n",
    "# Plot for each selected pair\n",
    "fig, axes = plt.subplots(len(selected_pairs), 1, figsize=(12, 4 * len(selected_pairs)), sharex=True)\n",
    "if len(selected_pairs) == 1:\n",
    "    axes = [axes]\n",
    "for i, (wid, pid) in enumerate(selected_pairs):\n",
    "    pair_df = pdf_sales_history[(pdf_sales_history['warehouse_id'] == wid) & (pdf_sales_history['product_id'] == pid)]\n",
    "    axes[i].plot(pair_df['week_start'], pair_df['weekly_sales'], marker='o')\n",
    "    axes[i].set_title(f'Warehouse {wid}, Product {pid} - Weekly Sales')\n",
    "    axes[i].set_ylabel('Weekly Sales')\n",
    "    axes[i].grid(True)\n",
    "plt.xlabel('Week Start')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8043c6d7-1749-4c25-ab63-2bb3c9129556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## Step 3: Visualize Weekly Sales Time Series for Selected Pairs\n",
    "We'll plot weekly sales trends for each of the selected (warehouse_id, product_id) pairs using matplotlib. This will help visually inspect trends, seasonality, and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d69de2c1-27ad-4ef6-ae41-2d4470504769",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure week_start is datetime\n",
    "pdf_sales_history['week_start'] = pd.to_datetime(pdf_sales_history['week_start'])\n",
    "\n",
    "# Plot for each selected pair\n",
    "fig, axes = plt.subplots(len(selected_pairs), 1, figsize=(12, 4 * len(selected_pairs)), sharex=True)\n",
    "if len(selected_pairs) == 1:\n",
    "    axes = [axes]\n",
    "for i, (wid, pid) in enumerate(selected_pairs):\n",
    "    pair_df = pdf_sales_history[(pdf_sales_history['warehouse_id'] == wid) & (pdf_sales_history['product_id'] == pid)]\n",
    "    axes[i].plot(pair_df['week_start'], pair_df['weekly_sales'], marker='o')\n",
    "    axes[i].set_title(f'Warehouse {wid}, Product {pid} - Weekly Sales')\n",
    "    axes[i].set_ylabel('Weekly Sales')\n",
    "    axes[i].grid(True)\n",
    "plt.xlabel('Week Start')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01 EDA and Visualization for Sales History Forecasting",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}